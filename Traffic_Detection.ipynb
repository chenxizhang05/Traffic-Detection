{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"l6zFIYX2bsSH"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xk4FU-jx9kc3"},"outputs":[],"source":["# This Colab requires TF 2.5.\n","!pip install -U \"tensorflow>=2.5\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yn5_uV1HLvaz"},"outputs":[],"source":["import os\n","import pathlib\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import re\n","import pandas as pd\n","import io\n","import scipy.misc\n","import numpy as np\n","from six import BytesIO\n","from PIL import Image, ImageDraw, ImageFont\n","from six.moves.urllib.request import urlopen\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","tf.get_logger().setLevel('ERROR')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-y9R0Xllefec"},"outputs":[],"source":["# @title Run this!!\n","\n","def load_image_into_numpy_array(path):\n","  \"\"\"Load an image from file into a numpy array.\n","\n","  Puts image into numpy array to feed into tensorflow graph.\n","  Note that by convention we put it into a numpy array with shape\n","  (height, width, channels), where channels=3 for RGB.\n","\n","  Args:\n","    path: the file path to the image\n","\n","  Returns:\n","    uint8 numpy array with shape (img_height, img_width, 3)\n","  \"\"\"\n","  image = None\n","  if(path.startswith('http')):\n","    response = urlopen(path)\n","    image_data = response.read()\n","    image_data = BytesIO(image_data)\n","    image = Image.open(image_data)\n","  else:\n","    image_data = tf.io.gfile.GFile(path, 'rb').read()\n","    image = Image.open(BytesIO(image_data))\n","\n","  (im_width, im_height) = image.size\n","  return np.array(image.getdata()).reshape(\n","      (1, im_height, im_width, 3)).astype(np.uint8)\n","\n","\n","ALL_MODELS = {\n","'CenterNet HourGlass104 512x512' : 'https://tfhub.dev/tensorflow/centernet/hourglass_512x512/1',\n","'CenterNet HourGlass104 Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/hourglass_512x512_kpts/1',\n","'CenterNet HourGlass104 1024x1024' : 'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024/1',\n","'CenterNet HourGlass104 Keypoints 1024x1024' : 'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024_kpts/1',\n","'CenterNet Resnet50 V1 FPN 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512/1',\n","'CenterNet Resnet50 V1 FPN Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512_kpts/1',\n","'CenterNet Resnet101 V1 FPN 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet101v1_fpn_512x512/1',\n","'CenterNet Resnet50 V2 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512/1',\n","'CenterNet Resnet50 V2 Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512_kpts/1',\n","'EfficientDet D0 512x512' : 'https://tfhub.dev/tensorflow/efficientdet/d0/1',\n","'EfficientDet D1 640x640' : 'https://tfhub.dev/tensorflow/efficientdet/d1/1',\n","'EfficientDet D2 768x768' : 'https://tfhub.dev/tensorflow/efficientdet/d2/1',\n","'EfficientDet D3 896x896' : 'https://tfhub.dev/tensorflow/efficientdet/d3/1',\n","'EfficientDet D4 1024x1024' : 'https://tfhub.dev/tensorflow/efficientdet/d4/1',\n","'EfficientDet D5 1280x1280' : 'https://tfhub.dev/tensorflow/efficientdet/d5/1',\n","'EfficientDet D6 1280x1280' : 'https://tfhub.dev/tensorflow/efficientdet/d6/1',\n","'EfficientDet D7 1536x1536' : 'https://tfhub.dev/tensorflow/efficientdet/d7/1',\n","'SSD MobileNet v2 320x320' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2',\n","'SSD MobileNet V1 FPN 640x640' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v1/fpn_640x640/1',\n","'SSD MobileNet V2 FPNLite 320x320' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1',\n","'SSD MobileNet V2 FPNLite 640x640' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_640x640/1',\n","'SSD ResNet50 V1 FPN 640x640 (RetinaNet50)' : 'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_640x640/1',\n","'SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)' : 'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_1024x1024/1',\n","'SSD ResNet101 V1 FPN 640x640 (RetinaNet101)' : 'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_640x640/1',\n","'SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)' : 'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_1024x1024/1',\n","'SSD ResNet152 V1 FPN 640x640 (RetinaNet152)' : 'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_640x640/1',\n","'SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)' : 'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_1024x1024/1',\n","'Faster R-CNN ResNet50 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1',\n","'Faster R-CNN ResNet50 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_1024x1024/1',\n","'Faster R-CNN ResNet50 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_800x1333/1',\n","'Faster R-CNN ResNet101 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_640x640/1',\n","'Faster R-CNN ResNet101 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_1024x1024/1',\n","'Faster R-CNN ResNet101 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_800x1333/1',\n","'Faster R-CNN ResNet152 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_640x640/1',\n","'Faster R-CNN ResNet152 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_1024x1024/1',\n","'Faster R-CNN ResNet152 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_800x1333/1',\n","'Faster R-CNN Inception ResNet V2 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_640x640/1',\n","'Faster R-CNN Inception ResNet V2 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_1024x1024/1',\n","'Mask R-CNN Inception ResNet V2 1024x1024' : 'https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1'\n","}\n","\n","COCO17_HUMAN_POSE_KEYPOINTS = [(0, 1),\n"," (0, 2),\n"," (1, 3),\n"," (2, 4),\n"," (0, 5),\n"," (0, 6),\n"," (5, 7),\n"," (7, 9),\n"," (6, 8),\n"," (8, 10),\n"," (5, 6),\n"," (5, 11),\n"," (6, 12),\n"," (11, 12),\n"," (11, 13),\n"," (13, 15),\n"," (12, 14),\n"," (14, 16)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oi28cqGGFWnY"},"outputs":[],"source":["# Clone the tensorflow models repository\n","!git clone --depth 1 https://github.com/tensorflow/models"]},{"cell_type":"markdown","metadata":{"id":"yX3pb_pXDjYA"},"source":["Installing the Object Detection API"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NwdsBdGhFanc"},"outputs":[],"source":["%%bash\n","sudo apt install -y protobuf-compiler\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install .\n","pip install numpy --upgrade\n"]},{"cell_type":"markdown","metadata":{"id":"3yDNgIx-kV7X"},"source":["Now we can import the dependencies we will need later"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2JCeQU3fkayh"},"outputs":[],"source":["from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5mucYUS6exUJ"},"outputs":[],"source":["PATH_TO_LABELS = './models/research/object_detection/data/mscoco_label_map.pbtxt'\n","category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HtwrSqvakTNn"},"outputs":[],"source":["#@title Model Selection { display-mode: \"form\", run: \"auto\" }\n","model_display_name = 'Faster R-CNN Inception ResNet V2 1024x1024' # @param ['CenterNet HourGlass104 512x512','CenterNet HourGlass104 Keypoints 512x512','CenterNet HourGlass104 1024x1024','CenterNet HourGlass104 Keypoints 1024x1024','CenterNet Resnet50 V1 FPN 512x512','CenterNet Resnet50 V1 FPN Keypoints 512x512','CenterNet Resnet101 V1 FPN 512x512','CenterNet Resnet50 V2 512x512','CenterNet Resnet50 V2 Keypoints 512x512','EfficientDet D0 512x512','EfficientDet D1 640x640','EfficientDet D2 768x768','EfficientDet D3 896x896','EfficientDet D4 1024x1024','EfficientDet D5 1280x1280','EfficientDet D6 1280x1280','EfficientDet D7 1536x1536','SSD MobileNet v2 320x320','SSD MobileNet V1 FPN 640x640','SSD MobileNet V2 FPNLite 320x320','SSD MobileNet V2 FPNLite 640x640','SSD ResNet50 V1 FPN 640x640 (RetinaNet50)','SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)','SSD ResNet101 V1 FPN 640x640 (RetinaNet101)','SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)','SSD ResNet152 V1 FPN 640x640 (RetinaNet152)','SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)','Faster R-CNN ResNet50 V1 640x640','Faster R-CNN ResNet50 V1 1024x1024','Faster R-CNN ResNet50 V1 800x1333','Faster R-CNN ResNet101 V1 640x640','Faster R-CNN ResNet101 V1 1024x1024','Faster R-CNN ResNet101 V1 800x1333','Faster R-CNN ResNet152 V1 640x640','Faster R-CNN ResNet152 V1 1024x1024','Faster R-CNN ResNet152 V1 800x1333','Faster R-CNN Inception ResNet V2 640x640','Faster R-CNN Inception ResNet V2 1024x1024','Mask R-CNN Inception ResNet V2 1024x1024']\n","model_handle = ALL_MODELS[model_display_name]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rBuD07fLlcEO"},"outputs":[],"source":["print('loading model...')\n","hub_model = hub.load(model_handle)\n","print('model loaded!')"]},{"cell_type":"code","source":["def filter_weird_small_box(output_d):\n","    '''\n","    Steps:\n","    1. calculate width and depth of boxes using normalized coordinates\n","    2. get a threshold for area, by referencing to roughly the largest-valid-detected boxes (here used: 11_March_4706_6.jpg, a truck with half yaxis tall)\n","    3. get a threshold for width (d1), coz it couldn't be too long also\n","    4.\n","    '''\n","    idx_to_del = []\n","    for k in range(len(output_d['detection_boxes'][0])):\n","        lst_1 = output_d['detection_boxes'][0][k]\n","        p1,p2,p3 = [lst_1[0],lst_1[1]],[lst_1[0],lst_1[3]],[lst_1[2],lst_1[3]]\n","        # d1,d2 = width,depth\n","        d1,d2 = ((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2)**0.5 , ((p2[0]-p3[0])**2 + (p2[1]-p3[1])**2)**0.5\n","        area = d1*d2\n","        scaling_factor = 1.3\n","        if d1 < 0.40 or d2 < 0.10: # this line is to filter the extreme wide and extreme tall boxes\n","            idx_to_del.append(k)\n","    idx_to_del = sorted(set(idx_to_del), reverse = True)\n","    for i in idx_to_del:\n","      output_d['detection_boxes'] = np.concatenate([output_d['detection_boxes'][:, :i], output_d['detection_boxes'][:, i+1:]], axis = 1)\n","      output_d['detection_classes'] = np.concatenate([output_d['detection_classes'][:, :i], output_d['detection_classes'][:, i+1:]], axis = 1)\n","      output_d['detection_scores'] = np.concatenate([output_d['detection_scores'][:, :i], output_d['detection_scores'][:, i+1:]], axis = 1)\n","    output_d['num_detections'] -= len(idx_to_del)\n","    return output_d\n","\n","\n","def filter_doublecount_overlap(output_d, overlap_thres):\n","    idx_to_del = []\n","    idx_done = []\n","\n","    valid_classes = [3.0, 6.0, 7.0, 8.0]\n","\n","    for k in range(len(output_d['detection_boxes'][0])):\n","        class_k = output_d['detection_classes'][0][k]\n","        lst_1 = output_d['detection_boxes'][0][k]\n","        idx_done.append(k)\n","\n","        for m in range(len(output_d['detection_boxes'][0])):\n","            if k != m:\n","                class_m = output_d['detection_classes'][0][m]\n","\n","                if class_k in valid_classes and class_m in valid_classes:\n","                    lst_2 = output_d['detection_boxes'][0][m]\n","                    lst_x, lst_y = [[lst_1[1],'1'], [lst_1[3],'1'],[lst_2[1],'2'], [lst_2[3],'2']],[[lst_1[0],'1'], [lst_1[2],'1'],[lst_2[0],'2'], [lst_2[2],'2']]\n","                    lst_x.sort(key=lambda x:x[0])\n","                    lst_y.sort(key=lambda x:x[0])\n","                    l_x, l_y = lst_1[3] - lst_1[1], lst_1[2] - lst_1[0]\n","\n","                    is_intersect = True\n","                    if lst_x[0][1] == lst_x[1][1] or lst_y[0][1] == lst_y[1][1]:\n","                        is_intersect = False\n","\n","                    exceed_x, exceed_y = False, False\n","                    if lst_x[2][0] - lst_x[1][0] > overlap_thres * l_x and is_intersect:\n","                        exceed_x = True\n","                    if lst_y[2][0] - lst_y[1][0] > overlap_thres * l_y and is_intersect:\n","                        exceed_y = True\n","\n","                    exceed_area = False\n","                    area_overlap = (lst_x[2][0] - lst_x[1][0]) * (lst_y[2][0] - lst_y[1][0])\n","                    area_box = l_x * l_y\n","                    if area_overlap > overlap_thres * area_box and is_intersect:\n","                        exceed_area = True\n","\n","                    is_doublecount = (exceed_x and exceed_y) or (exceed_x or exceed_area) and is_intersect\n","                    if is_doublecount and m not in idx_done and m not in idx_to_del:\n","                        idx_to_del.append(m)\n","\n","    idx_to_del = sorted(set(idx_to_del), reverse=True)\n","\n","    for i in idx_to_del:\n","      output_d['detection_boxes'] = np.concatenate([output_d['detection_boxes'][:, :i], output_d['detection_boxes'][:, i+1:]], axis = 1)\n","      output_d['detection_classes'] = np.concatenate([output_d['detection_classes'][:, :i], output_d['detection_classes'][:, i+1:]], axis = 1)\n","      output_d['detection_scores'] = np.concatenate([output_d['detection_scores'][:, :i], output_d['detection_scores'][:, i+1:]], axis = 1)\n","    output_d['num_detections'] -= len(idx_to_del)\n","    return output_d"],"metadata":{"id":"m2NSq_I4oQZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2O7rV8g9s8Bz"},"outputs":[],"source":["def display_box_for_image(image_np, i, day):\n","  ccount = 0\n","  count_car = 0\n","  count_motorcycle = 0\n","  count_bus = 0\n","  count_train = 0\n","  count_truck = 0\n","  bounding_box_coordinates = []\n","  # running inference\n","  results = hub_model(image_np)\n","  # print(results['detection_scores'][0])\n","  # print(results['detection_classes'][0])\n","\n","# different object detection models have additional results\n","# all of them are explained in the documentation\n","  result = {key:value.numpy() for key,value in results.items()}\n","\n","  label_id_offset = 0\n","  image_np_with_detections = image_np.copy()\n","# Use keypoints if available in detections\n","  keypoints, keypoint_scores = None, None\n","  if 'detection_keypoints' in result:\n","    keypoints = result['detection_keypoints'][0]\n","    keypoint_scores = result['detection_keypoint_scores'][0]\n","  #filter_weird_small_box(result)\n","  filter_doublecount_overlap(result, 0.3)\n","\n","  viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_np_with_detections[0],\n","      result['detection_boxes'][0],\n","      (result['detection_classes'][0] + label_id_offset).astype(int),\n","      result['detection_scores'][0],\n","      category_index,\n","      use_normalized_coordinates=True,\n","      max_boxes_to_draw=5,\n","      min_score_thresh=.30,\n","      agnostic_mode=False,\n","      keypoints=keypoints,\n","      keypoint_scores=keypoint_scores,\n","      keypoint_edges=COCO17_HUMAN_POSE_KEYPOINTS)\n","  plt.figure(figsize=(24,32))\n","  # plt.imshow(image_np_with_detections[0])\n","  # plt.show()\n","  im = Image.fromarray(image_np_with_detections[0])\n","  im.save(\"/content/drive/MyDrive/A*STAR Traffic Project/20230202/\"+str(day)+\"/Bounding Boxes__\" + str(i) + \"_.jpg\")\n","  bboxes = []\n","\n","  for i in range(len(result['detection_classes'][0])):\n","    if result['detection_classes'][0][i] == 3 and result['detection_scores'][0][i] > 0.30:\n","      bboxes.append((\"car\", result['detection_boxes'][0][i]))\n","      count_car+= 1\n","\n","  for i in range(len(result['detection_classes'][0])):\n","    if result['detection_classes'][0][i] == 4 and result['detection_scores'][0][i] > 0.30:\n","      bboxes.append((\"motorcycle\", result['detection_boxes'][0][i]))\n","      count_motorcycle+= 1\n","\n","  for i in range(len(result['detection_classes'][0])):\n","    if result['detection_classes'][0][i] == 6 and result['detection_scores'][0][i] > 0.30:\n","      bboxes.append((\"bus\", result['detection_boxes'][0][i]))\n","      count_bus+= 1\n","\n","  for i in range(len(result['detection_classes'][0])):\n","    if result['detection_classes'][0][i] == 7 and result['detection_scores'][0][i] > 0.30:\n","      bboxes.append((\"train\", result['detection_boxes'][0][i]))\n","      count_train+= 1\n","\n","  for i in range(len(result['detection_classes'][0])):\n","    if result['detection_classes'][0][i] == 8 and result['detection_scores'][0][i] > 0.30:\n","      bboxes.append((\"truck\", result['detection_boxes'][0][i]))\n","      count_truck+= 1\n","\n","  final_box = []\n","  for box in bboxes:\n","    ymin, xmin, ymax, xmax = box[1]\n","    final_box.append((box[0], [xmin * 1920, xmax * 1920, ymin * 1080, ymax * 1080]))\n","  ccount = count_car + count_motorcycle + count_bus + count_train + count_truck\n","\n","  return ccount, count_car, count_motorcycle, count_bus, count_train, count_truck, final_box"]},{"cell_type":"code","source":["def get_image_text_file(i, day):\n","  x = load_image_into_numpy_array(IMAGES_FOR_TEST['Cropped_Image' + str(i)])\n","  ccount, count_car, count_motorcycle, count_bus, count_train, count_truck, bounding_box_coordinates = display_box_for_image(x, i, day)\n","  frame_timestamp = 10 * (i-1)\n","  row = [str(day), frame_timestamp, count_car, count_motorcycle, count_bus, count_train, count_truck, ccount]\n","  df.loc[i-1] = row"],"metadata":{"id":"vC1bFSyek1WO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#the number of days in the list of\n","day_list =['GX240029', 'GX250029']"],"metadata":{"id":"gbN-6W9FIHJe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip3 install Pillow==9.5.0"],"metadata":{"id":"4PGJzq8-wk6n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for day in day_list:\n","  # Specify the directory containing the images\n","  image_directory = '/content/drive/MyDrive/A*STAR Traffic Project/20230202/' + str(day)\n","  # Get the list of files in the directory\n","  image_files = os.listdir(image_directory)\n","  # Get the list of files in the directory\n","  image_files = os.listdir(image_directory)\n","\n","  # Filter the list to include only image files\n","  image_files = [file for file in image_files if file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif'))]\n","\n","  # Create dictionaries to store the image paths\n","  images_dict = {}\n","  cropped_images_dict = {}\n","\n","  # Iterate over the image files and add them to the dictionaries\n","  for file in image_files:\n","      if 'Cropped_Image' in file:\n","          key = file.replace('.jpg', '').replace('.jpeg', '').replace('.png', '').replace('.gif', '')\n","          cropped_images_dict[key] = os.path.join(image_directory, file)\n","      elif 'Image' in file:\n","          key = file.replace('.jpg', '').replace('.jpeg', '').replace('.png', '').replace('.gif', '')\n","          images_dict[key] = os.path.join(image_directory, file)\n","\n","  # Combine both dictionaries\n","  IMAGES_FOR_TEST = {**images_dict, **cropped_images_dict}\n","\n","\n","  df = pd.DataFrame(columns=[\"video_filename\", \"frame / time-stamp\", \"model-cars\", \"model-motorcycles\", \"model-bus\", \"model-train\", \"model-truck\", \"model-vehicles\"])\n","\n","  largest_number = max(int(re.search(r'\\d+', key).group()) for key in IMAGES_FOR_TEST.keys())\n","  for i in range(1, largest_number+1):\n","    get_image_text_file(i, day)\n","\n","  excel_file_path = \"/content/drive/MyDrive/A*STAR Traffic Project/20230202/\" + str(day) + \".xlsx\"\n","  df.to_excel(excel_file_path, sheet_name=\"Data\", index=False)"],"metadata":{"id":"JxsHAjptIxxA"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1fJNqQGaw01uDhhNOv4Yc_HhcYgrqaugY","timestamp":1692288195619}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}